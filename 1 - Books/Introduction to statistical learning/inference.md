
**Statistical inference** is the process of using data to [[estimate]], **test**, and **quantify uncertainty** about unknown quantities ([[parameter]], effect, or [[distribution]]) that describe how the data were generated.

In the inference paradigm we are interested in understanding the association between $Y$ and $X_1, \dots , X_p$ this mean that, difference in [[prediction]] paradigm, $\hat{f}$ cannot be a **black box** because understand the $\hat{f}$ function are going to give us the answer of the relationship between $Y$ and $X_1, \dots , X_p$

## What inference is (and isnâ€™t)

- It focuses on **uncertainty-aware claims** (interval, test, [[posterior distribution]]).
- Inference is not the same as [[prediction]]: you can predict well without understanding mechanisms, and you can infer mechanisms without maximizing predictive accuracy.

This setting allow us to answer the following questions:

- Which predictors are associated with the response?
- What is the relationship between the response and each predictor?
- Can the relationship between $Y$ and each predictor be adequately summarized using a linear equation, or is the relationship more complicated?
