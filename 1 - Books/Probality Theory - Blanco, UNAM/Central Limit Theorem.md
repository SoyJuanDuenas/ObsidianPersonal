#inferential_statistics #probability

Central Limit Theorem is one of the most important result in probability theory, this theorem says: 

> [!NOTE] 
> Suppose $\{X_1, ... , X_n\}$ is a sequence of iid [[random variable]] having a distribution with a [[expected value]]  $\mu$ and finite [[variance]] $\sigma^2$. Then, as n approaches infinity, the [[random variable]] $\sqrt{n}(\overline{X}_n - \mu)$ [[converge in distribution]] to a normal $N(0, \sigma^2)$  

# Proof

# Conditions for the Central Limit Theorem

- Sampled observations must be independent, for this reason we take random samples or random assignments,  and if we have a sampling without replacement, n (sample size) must <10% of the population.
- Either the population distribution is normal, or if the population distribution is skewed the larger sample size we need for the Central Limit Theorem apply, for skew distributions usually more than 30 sample size is properly.


### References

To develop this chunk we will use the next one online course as our main source

- YouTube https://www.youtube.com/playlist?list=PLc_ATubXG-SSBl1JtXZHGvKLfyqUs6ETl
- Coursera Inferential Statistics - Duke University
